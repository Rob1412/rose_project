{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 Transfer Learning Model (LOCAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install splitfolders library (in order to apply \"train-val-test-split\" to our data):\n",
    "\n",
    "! pip install split-folders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "\n",
    "# CHECK THESE DIRECTORIES BEFORE RUNNING CELL!\n",
    "\n",
    "raw_data_path = \"../raw_data/flowers\"\n",
    "\n",
    "split_data_path =  \"../raw_data/split_folder\"\n",
    "\n",
    "# Split: 80% train, 10% val and 10% test:\n",
    "\n",
    "splitfolders.ratio(raw_data_path, output=split_data_path, seed=42, ratio=(.8, .1, .1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train, validation, and test data:\n",
    "\n",
    "train_data_dir = split_data_path+\"/train/\" # CHECK THIS DIRECTORY!\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=(128,128),\n",
    "    batch_size=32,\n",
    "    seed=42)\n",
    "\n",
    "val_data_dir = split_data_path+\"/val/\" # CHECK THIS DIRECTORY!\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    val_data_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=(128,128),\n",
    "    batch_size=32,\n",
    "    seed=42)\n",
    "\n",
    "test_data_dir = split_data_path+\"/test/\" # CHECK THIS DIRECTORY!\n",
    "\n",
    "test_ds = image_dataset_from_directory(\n",
    "    test_data_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=(128,128),\n",
    "    batch_size=32,\n",
    "    seed=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data augmentation layers:\n",
    "\n",
    "data_augmentation = models.Sequential()\n",
    "\n",
    "data_augmentation.add(layers.RandomFlip(\"horizontal\"))\n",
    "data_augmentation.add(layers.RandomZoom((0.1, 0.2)))\n",
    "data_augmentation.add(layers.RandomTranslation(0.2, 0.2))\n",
    "data_augmentation.add(layers.RandomRotation(0.1))\n",
    "\n",
    "# Load VGG16 model from tensorflow:\n",
    "\n",
    "vgg16_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(128,128,3))\n",
    "\n",
    "# Make sure we don't re-train the parameters:\n",
    "\n",
    "vgg16_model.trainable = False\n",
    "\n",
    "# Create the final layers, specific to our task:\n",
    "\n",
    "flatten_layer = layers.Flatten()\n",
    "dense_layer_1 = layers.Dense(512, activation='relu')\n",
    "dropout_1 = layers.Dropout(0.3)\n",
    "dense_layer_2 = layers.Dense(256, activation='relu')\n",
    "dropout_2 = layers.Dropout(0.4)\n",
    "prediction_layer = layers.Dense(16, activation='softmax')\n",
    "\n",
    "# Create full model architecture suited to our task:\n",
    "\n",
    "inputs = layers.Input(shape = (128, 128, 3))\n",
    "\n",
    "x = data_augmentation(inputs) # We still have our data augmentation layers\n",
    "\n",
    "x = preprocess_input(x) # Then a preprocessing layer specifically designed for the VGG16\n",
    "\n",
    "x = vgg16_model(x) # Then our transfer learning model\n",
    "\n",
    "x = layers.Flatten()(x) # Flatten image tensors\n",
    "\n",
    "x = layers.Dense(512, activation = \"relu\")(x) # Add a dense layer with dropout\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(256, activation = \"relu\")(x) # Add another dense layer with dropout\n",
    "x = layers.Dropout(0.4)(x)\n",
    "\n",
    "pred = layers.Dense(16, activation = \"softmax\")(x) # Add the prediction layer for 16-class classification\n",
    "\n",
    "# Use the keras functional API to create our model:\n",
    "\n",
    "final_model = models.Model(inputs = inputs, outputs = pred)\n",
    "\n",
    "# Compile the model:\n",
    "\n",
    "final_model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WARNING: DO NOT RUN LOCALLY - VERY SLOW!!! ###\n",
    "##################################################\n",
    "\n",
    "# Fit the model:\n",
    "\n",
    "es = EarlyStopping(patience=10,\n",
    "                   restore_best_weights=True,\n",
    "                   monitor='val_loss')\n",
    "\n",
    "lr = ReduceLROnPlateau(monitor=\"val_loss\",\n",
    "                       factor=0.1,\n",
    "                       patience=3,\n",
    "                       min_lr=0)\n",
    "\n",
    "mcp = ModelCheckpoint(\"vgg16_tl_model.h5\",\n",
    "                      save_weights_only=False,\n",
    "                      monitor='val_loss',\n",
    "                      save_best_only=True)\n",
    "\n",
    "history = final_model.fit(train_ds, epochs=200, validation_data=val_ds, callbacks=[es,lr,mcp], verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plot History (Loss & Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Create a subplot with 1 row and 2 columns\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot the accuracy graph on the first subplot\n",
    "ax1.plot(train_acc, label='Training Accuracy')\n",
    "ax1.plot(val_acc, label='Validation Accuracy')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend(loc='best')\n",
    "ax1.set_title('Training and Validation Accuracy')\n",
    "\n",
    "# Plot the loss graph on the second subplot\n",
    "ax2.plot(train_loss, label='Training Loss')\n",
    "ax2.plot(val_loss, label='Validation Loss')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend(loc='best')\n",
    "ax2.set_title('Training and Validation Loss')\n",
    "\n",
    "# Display the graphs\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rose_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
